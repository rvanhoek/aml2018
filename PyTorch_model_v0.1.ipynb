{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quora Question Pairs \n",
    "\n",
    "Can you identify question pairs that have the same intent?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_labels = pd.read_csv('train_labels.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# print(training_labels)\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Preprocessing\n",
    "    \n",
    "_The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form._\n",
    "\n",
    "_However, the two words differ in their flavor. Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split test data\n",
      "========= Clean testing data question 1 ====================\n",
      "***** Regularizing *****\n",
      "***** Filtering *****\n",
      "========= Clean testing data question 1 ====================\n",
      "***** Regularizing *****\n",
      "***** Filtering *****\n",
      "========= Finish preprocessing of data ==========\n"
     ]
    }
   ],
   "source": [
    "def text_regularize(dataframe):\n",
    "    print ('***** Regularizing *****')\n",
    "    # stemming\n",
    "    \n",
    "    \n",
    "    # lematizing\n",
    "    \n",
    "    \n",
    " \n",
    "def text_filtering(dataframe):\n",
    "    print ('***** Filtering *****')\n",
    "    \n",
    "    # import regular expression\n",
    "    import re\n",
    "    \n",
    "    # remove stopwords\n",
    "    \n",
    "    # remove special symbols with regular expression\n",
    "        \n",
    "\n",
    "\n",
    "print('Split test data')\n",
    "test_q1 = test_data['question1']\n",
    "test_q2 = test_data['question2']       \n",
    "    \n",
    "print('========= Clean testing data question 1 ====================')\n",
    "# Do cleaning\n",
    "text_regularize(test_q1)\n",
    "text_filtering(test_q1)\n",
    "\n",
    "print('========= Clean testing data question 1 ====================')\n",
    "# Do cleaning\n",
    "text_regularize(test_q2)\n",
    "text_filtering(test_q2)\n",
    "\n",
    "# Save as new file\n",
    "test_q1.to_csv('test_q1.csv')\n",
    "\n",
    "print('========= Finish preprocessing of data ==========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Word2vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
