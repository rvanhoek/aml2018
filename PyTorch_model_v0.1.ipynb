{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quora Question Pairs \n",
    "\n",
    "Can you identify question pairs that have the same intent?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "from nltk.corpus import brown\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\wiets\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\wiets\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\wiets\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Eenmalig downloaden\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('brown')\n",
    "\n",
    "# Voorkomen onterechte warnings\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Porter of Lancaster stemmers - tweede is 'aggressiever' dan de eerste.\n",
    "porter = PorterStemmer()\n",
    "lancaster=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functie voor stemming (met Porter)\n",
    "\n",
    "def stemSentence(sentence):\n",
    "   \n",
    "    # tokenize\n",
    "    token_words=word_tokenize(sentence)\n",
    "    \n",
    "    # stemming\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functie voor lemmatizing\n",
    "\"\"\"\n",
    "\"Lemmatization, unlike Stemming, reduces the inflected words properly ensuring that the root word belongs to the language.\"\n",
    "Lemmatization is waarschijnlijk beter dan stemming in ons project omdat de betekenis van de woorden erg belangrijk is \n",
    "\"\"\"\n",
    "\n",
    "def lemSentence(sentence):\n",
    "    \n",
    "    # tokenize\n",
    "    token_words=word_tokenize(sentence)\n",
    "    \n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # lemmatize\n",
    "    lem_sentence=[]\n",
    "    for word in token_words:   \n",
    "        lem_sentence.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        lem_sentence.append(\" \")\n",
    "    \n",
    "    return \"\".join(lem_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Testen van functies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  qid1  qid2                                          question1  \\\n",
      "0   0     1     2  What is the step by step guide to invest in sh...   \n",
      "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
      "2   2     5     6  How can I increase the speed of my internet co...   \n",
      "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
      "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
      "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
      "6   6    13    14                                Should I buy tiago?   \n",
      "7   7    15    16                     How can I be a good geologist?   \n",
      "8   8    17    18                    When do you use シ instead of し?   \n",
      "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
      "\n",
      "                                           question2  is_duplicate  \n",
      "0  What is the step by step guide to invest in sh...             0  \n",
      "1  What would happen if the Indian government sto...             0  \n",
      "2  How can Internet speed be increased by hacking...             0  \n",
      "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
      "4            Which fish would survive in salt water?             0  \n",
      "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
      "6  What keeps childern active and far from phone ...             0  \n",
      "7          What should I do to be a great geologist?             1  \n",
      "8              When do you use \"&\" instead of \"and\"?             0  \n",
      "9  How do I hack Motorola DCX3400 for free internet?             0  \n"
     ]
    }
   ],
   "source": [
    "# Train data inladen en tijdelijk eerste paar regels om functies te checken\n",
    "\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "train_data_head=train_data[:10].copy()\n",
    "\n",
    "print(train_data_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  qid1  qid2                                          question1  \\\n",
      "0   0     1     2  What is the step by step guide to invest in sh...   \n",
      "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
      "2   2     5     6  How can I increase the speed of my internet co...   \n",
      "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
      "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
      "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
      "6   6    13    14                                Should I buy tiago?   \n",
      "7   7    15    16                     How can I be a good geologist?   \n",
      "8   8    17    18                    When do you use シ instead of し?   \n",
      "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
      "\n",
      "                                           question2  is_duplicate  \\\n",
      "0  What is the step by step guide to invest in sh...             0   \n",
      "1  What would happen if the Indian government sto...             0   \n",
      "2  How can Internet speed be increased by hacking...             0   \n",
      "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
      "4            Which fish would survive in salt water?             0   \n",
      "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1   \n",
      "6  What keeps childern active and far from phone ...             0   \n",
      "7          What should I do to be a great geologist?             1   \n",
      "8              When do you use \"&\" instead of \"and\"?             0   \n",
      "9  How do I hack Motorola DCX3400 for free internet?             0   \n",
      "\n",
      "                                      question1_stem  \\\n",
      "0  what is the step by step guid to invest in sha...   \n",
      "1  what is the stori of kohinoor ( koh-i-noor ) d...   \n",
      "2  how can I increas the speed of my internet con...   \n",
      "3   whi am I mental veri lone ? how can I solv it ?    \n",
      "4  which one dissolv in water quikli sugar , salt...   \n",
      "5  astrolog : I am a capricorn sun cap moon and c...   \n",
      "6                              should I buy tiago ?    \n",
      "7                   how can I be a good geologist ?    \n",
      "8                  when do you use シ instead of し ?    \n",
      "9  motorola ( compani ) : can I hack my charter m...   \n",
      "\n",
      "                                      question2_stem  \n",
      "0  what is the step by step guid to invest in sha...  \n",
      "1  what would happen if the indian govern stole t...  \n",
      "2  how can internet speed be increas by hack thro...  \n",
      "3  find the remaind when [ math ] 23^ { 24 } [ /m...  \n",
      "4           which fish would surviv in salt water ?   \n",
      "5  I 'm a tripl capricorn ( sun , moon and ascend...  \n",
      "6  what keep childern activ and far from phone an...  \n",
      "7        what should I do to be a great geologist ?   \n",
      "8    when do you use `` & '' instead of `` and '' ?   \n",
      "9  how do I hack motorola dcx3400 for free intern...  \n"
     ]
    }
   ],
   "source": [
    "# Toepassen van stemming functie op Train data\n",
    "\n",
    "train_data_head['question1_stem'] = train_data_head['question1'].apply(stemSentence)\n",
    "train_data_head['question2_stem'] = train_data_head['question2'].apply(stemSentence)\n",
    "\n",
    "print(train_data_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  qid1  qid2                                          question1  \\\n",
      "0   0     1     2  What is the step by step guide to invest in sh...   \n",
      "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
      "2   2     5     6  How can I increase the speed of my internet co...   \n",
      "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
      "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
      "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
      "6   6    13    14                                Should I buy tiago?   \n",
      "7   7    15    16                     How can I be a good geologist?   \n",
      "8   8    17    18                    When do you use シ instead of し?   \n",
      "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
      "\n",
      "                                           question2  is_duplicate  \\\n",
      "0  What is the step by step guide to invest in sh...             0   \n",
      "1  What would happen if the Indian government sto...             0   \n",
      "2  How can Internet speed be increased by hacking...             0   \n",
      "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
      "4            Which fish would survive in salt water?             0   \n",
      "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1   \n",
      "6  What keeps childern active and far from phone ...             0   \n",
      "7          What should I do to be a great geologist?             1   \n",
      "8              When do you use \"&\" instead of \"and\"?             0   \n",
      "9  How do I hack Motorola DCX3400 for free internet?             0   \n",
      "\n",
      "                                      question1_stem  \\\n",
      "0  what is the step by step guid to invest in sha...   \n",
      "1  what is the stori of kohinoor ( koh-i-noor ) d...   \n",
      "2  how can I increas the speed of my internet con...   \n",
      "3   whi am I mental veri lone ? how can I solv it ?    \n",
      "4  which one dissolv in water quikli sugar , salt...   \n",
      "5  astrolog : I am a capricorn sun cap moon and c...   \n",
      "6                              should I buy tiago ?    \n",
      "7                   how can I be a good geologist ?    \n",
      "8                  when do you use シ instead of し ?    \n",
      "9  motorola ( compani ) : can I hack my charter m...   \n",
      "\n",
      "                                      question2_stem  \\\n",
      "0  what is the step by step guid to invest in sha...   \n",
      "1  what would happen if the indian govern stole t...   \n",
      "2  how can internet speed be increas by hack thro...   \n",
      "3  find the remaind when [ math ] 23^ { 24 } [ /m...   \n",
      "4           which fish would surviv in salt water ?    \n",
      "5  I 'm a tripl capricorn ( sun , moon and ascend...   \n",
      "6  what keep childern activ and far from phone an...   \n",
      "7        what should I do to be a great geologist ?    \n",
      "8    when do you use `` & '' instead of `` and '' ?    \n",
      "9  how do I hack motorola dcx3400 for free intern...   \n",
      "\n",
      "                                       question1_lem  \\\n",
      "0  What be the step by step guide to invest in sh...   \n",
      "1  What be the story of Kohinoor ( Koh-i-Noor ) D...   \n",
      "2  How can I increase the speed of my internet co...   \n",
      "3  Why be I mentally very lonely ? How can I solv...   \n",
      "4  Which one dissolve in water quikly sugar , sal...   \n",
      "5  Astrology : I be a Capricorn Sun Cap moon and ...   \n",
      "6                              Should I buy tiago ?    \n",
      "7                   How can I be a good geologist ?    \n",
      "8                  When do you use シ instead of し ?    \n",
      "9  Motorola ( company ) : Can I hack my Charter M...   \n",
      "\n",
      "                                       question2_lem  \n",
      "0  What be the step by step guide to invest in sh...  \n",
      "1  What would happen if the Indian government ste...  \n",
      "2  How can Internet speed be increase by hack thr...  \n",
      "3  Find the remainder when [ math ] 23^ { 24 } [ ...  \n",
      "4          Which fish would survive in salt water ?   \n",
      "5  I 'm a triple Capricorn ( Sun , Moon and ascen...  \n",
      "6  What keep childern active and far from phone a...  \n",
      "7        What should I do to be a great geologist ?   \n",
      "8    When do you use `` & '' instead of `` and '' ?   \n",
      "9  How do I hack Motorola DCX3400 for free intern...  \n"
     ]
    }
   ],
   "source": [
    "# Toepassen van lemmatization functie op Train data\n",
    "\n",
    "train_data_head['question1_lem'] = train_data_head['question1'].apply(lemSentence)\n",
    "train_data_head['question2_lem'] = train_data_head['question2'].apply(lemSentence)\n",
    "\n",
    "print(train_data_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- SAVE BROWN CORPUS MODEL ----\n",
      "0.912204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wiets\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/@mishra.thedeepak/word2vec-in-minutes-gensim-nlp-python-6940f4e00980\n",
    "\n",
    "# create trained model\n",
    "sentences = brown.sents()\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "print('---- SAVE BROWN CORPUS MODEL ----')\n",
    "model.save('brown_model')\n",
    "\n",
    "# create brown_model\n",
    "model = gensim.models.Word2Vec.load('brown_model')\n",
    "\n",
    "# find similarity of words\n",
    "print(model.similarity('woman', 'man'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wiets\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "C:\\Users\\wiets\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5\n",
    "# https://datascience.stackexchange.com/questions/23969/sentence-similarity-prediction\n",
    "\n",
    "# create model\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(question1)]\n",
    "\n",
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "\n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_infer [ 0.01910738  0.01698834 -0.01945818 -0.0152849   0.00559611  0.01271356\n",
      "  0.02366393 -0.00546236 -0.00389903 -0.0077853   0.00632725  0.02083503\n",
      "  0.01776579 -0.00873339  0.00331536  0.0104358  -0.00993257 -0.01187992\n",
      " -0.01308167 -0.00776289]\n",
      "[('0', -0.1929418444633484)]\n",
      "[ -1.42748412e-02  -1.85315013e-02  -1.62658957e-03   1.52987000e-02\n",
      "  -8.50031618e-03  -2.54184455e-02  -2.23779939e-02   1.00819319e-02\n",
      "  -2.08196566e-02  -1.57111138e-02  -8.49933270e-03   1.05077894e-02\n",
      "  -1.42097082e-02  -2.52882182e-03   1.86181590e-02   9.18155070e-03\n",
      "   1.12419454e-02   1.83722388e-03  -5.49770375e-05   5.54856192e-03]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "#to find the vector of a document which is not in training data\n",
    "test_data = word_tokenize(\"I love chatbots\".lower())\n",
    "v1 = model.infer_vector(test_data)\n",
    "print(\"V1_infer\", v1)\n",
    "\n",
    "# to find most similar doc using tags\n",
    "similar_doc = model.docvecs.most_similar('1')\n",
    "print(similar_doc)\n",
    "\n",
    "# to find vector of doc in training data using tags or in other words, printing the vector of document at index 1 in training data\n",
    "print(model.docvecs['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   qid1                                     question1_stem\n",
      "0     1  what is the step by step guid to invest in sha...\n",
      "1     3  what is the stori of kohinoor ( koh-i-noor ) d...\n",
      "2     5  how can I increas the speed of my internet con...\n",
      "3     7   whi am I mental veri lone ? how can I solv it ? \n",
      "4     9  which one dissolv in water quikli sugar , salt...\n",
      "5    11  astrolog : I am a capricorn sun cap moon and c...\n",
      "6    13                              should I buy tiago ? \n",
      "7    15                   how can I be a good geologist ? \n",
      "8    17                  when do you use シ instead of し ? \n",
      "9    19  motorola ( compani ) : can I hack my charter m...\n",
      "   qid2                                     question2_stem\n",
      "0     2  what is the step by step guid to invest in sha...\n",
      "1     4  what would happen if the indian govern stole t...\n",
      "2     6  how can internet speed be increas by hack thro...\n",
      "3     8  find the remaind when [ math ] 23^ { 24 } [ /m...\n",
      "4    10           which fish would surviv in salt water ? \n",
      "5    12  I 'm a tripl capricorn ( sun , moon and ascend...\n",
      "6    14  what keep childern activ and far from phone an...\n",
      "7    16        what should I do to be a great geologist ? \n",
      "8    18    when do you use `` & '' instead of `` and '' ? \n",
      "9    20  how do I hack motorola dcx3400 for free intern...\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model = Doc2Vec.load(\"d2v.model\")\n",
    "\n",
    "question1 = train_data_head[['qid1', 'question1_stem']].copy()\n",
    "print(question1)\n",
    "question2 = train_data_head[['qid2', 'question2_stem']].copy()\n",
    "print(question2)\n",
    "\n",
    "# get similarity of two rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "training_labels = pd.read_csv('train_labels.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "#print(train_data)\n",
    "#print(training_labels)\n",
    "#print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Preprocessing\n",
    "    \n",
    "_The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form._\n",
    "\n",
    "_However, the two words differ in their flavor. Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split test data\n",
      "========= Clean testing data question 1 ====================\n",
      "***** Regularizing *****\n",
      "***** Filtering *****\n",
      "========= Clean testing data question 1 ====================\n",
      "***** Regularizing *****\n",
      "***** Filtering *****\n",
      "========= Finish preprocessing of data ==========\n"
     ]
    }
   ],
   "source": [
    "def text_regularize(dataframe):\n",
    "    print ('***** Regularizing *****')\n",
    "    # stemming\n",
    "    \n",
    "    \n",
    "    # lematizing\n",
    "    \n",
    "    \n",
    " \n",
    "def text_filtering(dataframe):\n",
    "    print ('***** Filtering *****')\n",
    "    \n",
    "    # import regular expression\n",
    "    import re\n",
    "    \n",
    "    # remove stopwords\n",
    "    \n",
    "    \n",
    "    # remove special symbols with regular expression\n",
    "        \n",
    "\n",
    "\n",
    "print('Split test data')\n",
    "test_q1 = test_data['question1']\n",
    "test_q2 = test_data['question2']       \n",
    "    \n",
    "print('========= Clean testing data question 1 ====================')\n",
    "# Do cleaning\n",
    "text_regularize(test_q1)\n",
    "text_filtering(test_q1)\n",
    "\n",
    "print('========= Clean testing data question 2 ====================')\n",
    "# Do cleaning\n",
    "text_regularize(test_q2)\n",
    "text_filtering(test_q2)\n",
    "\n",
    "# Save as new file\n",
    "test_q1.to_csv('test_q1.csv')\n",
    "\n",
    "print('========= Finish preprocessing of data ==========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Word2vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
